<p>Start at an initial position <span class="math inline">\boldsymbol{\theta}^{(0)}</span>. For iterations <span class="math inline">t = 1,\ldots,T</span>:</p>
<ol>
  <li>Generate a proposal <span class="math inline">\boldsymbol{\theta}'</span> from <span class="math inline">q(\boldsymbol{\theta}' \mid \boldsymbol{\theta}^{(t-1)})</span></li>
  <li>Calculate the acceptance probability <span class="math inline">\alpha(\boldsymbol{\theta}', \boldsymbol{\theta}^{(t-1)})</span></li>
  <li>Draw <span class="math inline">u \sim \text{Uniform}(0,1)</span></li>
  <li>If <span class="math inline">u < \alpha(\boldsymbol{\theta}', \boldsymbol{\theta}^{(t-1)})</span>, set <span class="math inline">\boldsymbol{\theta}^{(t)} = \boldsymbol{\theta}'</span>; otherwise set <span class="math inline">\boldsymbol{\theta}^{(t)} = \boldsymbol{\theta}^{(t-1)}</span></li>
</ol>
<h4>Resources</h4>
<p>Further details on the Metropolis-Hastings algorithm can be found here:</p>
<ul>
  <li><a href="https://bayes.wustl.edu/Manual/EquationOfState.pdf">Equation of State Calculations by Fast Computing Machines</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolisâ€“Hastings algorithm</a></li>
  <li><a href="https://www.routledge.com/Handbook-of-Markov-Chain-Monte-Carlo/Brooks-Gelman-Jones-Meng/p/book/9781420079418">Handbook of Markov Chain Monte Carlo</a></li>
</ul>
